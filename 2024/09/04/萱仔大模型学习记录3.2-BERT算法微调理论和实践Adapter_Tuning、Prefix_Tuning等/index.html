<!DOCTYPE html>
<html lang=zh>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="renderer" content="webkit">
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="format-detection" content="telephone=no,email=no,adress=no">
  <!-- Color theme for statusbar -->
  <meta name="theme-color" content="#000000" />
  <!-- 强制页面在当前窗口以独立页面显示,防止别人在框架里调用页面 -->
  <meta http-equiv="window-target" content="_top" />
  
  
  <title>萱仔大模型学习记录3.2-BERT算法微调理论和实践Adapter_Tuning、Prefix_Tuning等 | 萱仔的学习小屋</title>
  <meta name="description" content="进行大模型的学习记录，包括了大模型原理，nlp常用的bert算法和transform学习，一些项目的代码和langchain等框架的入门学习过程">
<meta property="og:type" content="article">
<meta property="og:title" content="萱仔大模型学习记录3.2-BERT算法微调理论和实践Adapter_Tuning、Prefix_Tuning等">
<meta property="og:url" content="http://example.com/2024/09/04/%E8%90%B1%E4%BB%94%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%953.2-BERT%E7%AE%97%E6%B3%95%E5%BE%AE%E8%B0%83%E7%90%86%E8%AE%BA%E5%92%8C%E5%AE%9E%E8%B7%B5Adapter_Tuning%E3%80%81Prefix_Tuning%E7%AD%89/index.html">
<meta property="og:site_name" content="萱仔的学习小屋">
<meta property="og:description" content="进行大模型的学习记录，包括了大模型原理，nlp常用的bert算法和transform学习，一些项目的代码和langchain等框架的入门学习过程">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i-blog.csdnimg.cn/direct/efe6d6d5a3144eb99246e3b0043a4f30.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/direct/184bb99124584ebeb5d4e06af1de877c.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/direct/90fab1326f604ce68fda4c25c2773666.png">
<meta property="article:published_time" content="2024-09-04T06:00:00.000Z">
<meta property="article:modified_time" content="2024-09-09T03:01:51.551Z">
<meta property="article:author" content="xuanzaismart">
<meta property="article:tag" content="技术, 教程">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i-blog.csdnimg.cn/direct/efe6d6d5a3144eb99246e3b0043a4f30.png">
  <!-- Canonical links -->
  <link rel="canonical" href="http://example.com/2024/09/04/%E8%90%B1%E4%BB%94%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%953.2-BERT%E7%AE%97%E6%B3%95%E5%BE%AE%E8%B0%83%E7%90%86%E8%AE%BA%E5%92%8C%E5%AE%9E%E8%B7%B5Adapter_Tuning%E3%80%81Prefix_Tuning%E7%AD%89/index.html">
  
    <link rel="alternate" href="[object Object]" title="萱仔的学习小屋" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png" type="image/x-icon">
  
  
<link rel="stylesheet" href="/css/style.css">

  
  
  
  
<meta name="generator" content="Hexo 7.3.0"></head>


<body class="main-center theme-black" itemscope itemtype="http://schema.org/WebPage">
  <header class="header" itemscope itemtype="http://schema.org/WPHeader">
  <div class="slimContent">
    <div class="navbar-header">
      
      
      <div class="profile-block text-center">
        <a id="avatar" href="https://blog.csdn.net/qq_44117805?" target="_blank">
          <img class="img-circle img-rotate" src="/images/avatar.jpg" width="200" height="200">
        </a>
        <h2 id="name" class="hidden-xs hidden-sm">萱仔</h2>
        <h3 id="title" class="hidden-xs hidden-sm hidden-md">萱仔的自我学习记录，冲冲冲！</h3>
        <small id="location" class="text-muted hidden-xs hidden-sm"><i class="icon icon-map-marker"></i> Hebei, China</small>
      </div>
      
      <div class="search" id="search-form-wrap">

    <form class="search-form sidebar-form">
        <div class="input-group">
            <input type="text" class="search-form-input form-control" placeholder="搜索" />
            <span class="input-group-btn">
                <button type="submit" class="search-form-submit btn btn-flat" onclick="return false;"><i class="icon icon-search"></i></button>
            </span>
        </div>
    </form>
    <div class="ins-search">
  <div class="ins-search-mask"></div>
  <div class="ins-search-container">
    <div class="ins-input-wrapper">
      <input type="text" class="ins-search-input" placeholder="想要查找什么..." x-webkit-speech />
      <button type="button" class="close ins-close ins-selectable" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
    </div>
    <div class="ins-section-wrapper">
      <div class="ins-section-container"></div>
    </div>
  </div>
</div>


</div>
      <button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <nav id="main-navbar" class="collapse navbar-collapse" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation">
      <ul class="nav navbar-nav main-nav menu-highlight">
        
        
        <li class="menu-item menu-item-home">
          <a href="/.">
            
            <i class="icon icon-home-fill"></i>
            
            <span class="menu-title">首页</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-archives">
          <a href="/archives">
            
            <i class="icon icon-archives-fill"></i>
            
            <span class="menu-title">归档</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-categories">
          <a href="/categories">
            
            <i class="icon icon-folder"></i>
            
            <span class="menu-title">分类</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-tags">
          <a href="/tags">
            
            <i class="icon icon-tags"></i>
            
            <span class="menu-title">标签</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-repository">
          <a href="/repository">
            
            <i class="icon icon-project"></i>
            
            <span class="menu-title">项目</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-books">
          <a href="/books">
            
            <i class="icon icon-book-fill"></i>
            
            <span class="menu-title">书单</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-links">
          <a href="/links">
            
            <i class="icon icon-friendship"></i>
            
            <span class="menu-title">友链</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-about">
          <a href="/about">
            
            <i class="icon icon-cup-fill"></i>
            
            <span class="menu-title">关于</span>
          </a>
        </li>
        
      </ul>
      
	
    <ul class="social-links">
    	
        <li><a href="https://blog.csdn.net/qq_44117805?" target="_blank" title="CSDN" data-toggle=tooltip data-placement=top><i class="icon icon-CSDN"></i></a></li>
        
        <li><a href="/atom.xml" target="_blank" title="Rss" data-toggle=tooltip data-placement=top><i class="icon icon-rss"></i></a></li>
        
    </ul>

    </nav>
  </div>
</header>

  
    <aside class="sidebar" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    
      <div class="widget">
    <h3 class="widget-title">公告</h3>
    <div class="widget-body">
        <div id="board">
            <div class="content">
                <p>不问收获，但问耕耘！冲冲冲，萱仔的自我学习记录博客，恭喜自己重新在github搭建个人博客，前面内容逐渐搬运到新博客之后和原CSDN博客同时更新，<br>CSDN网址：<a href="https://blog.csdn.net/qq_44117805?type=blog" target="_blank">https://blog.csdn.net/qq_44117805?type=blog</a></p>
            </div>
        </div>
    </div>
</div>

    
      
  <div class="widget">
    <h3 class="widget-title">分类</h3>
    <div class="widget-body">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/">大模型学习记录</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8A%80%E6%9C%AF/">技术</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/">推荐算法学习记录</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%96%B0%E9%97%BB%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E9%A1%B9%E7%9B%AE/">新闻文本分类项目</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%8E%AF%E5%A2%83/">环境</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%8E%AF%E5%A2%83/Python/">Python</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%90%B1%E4%BB%94%E6%B1%82%E8%81%8C%E7%B3%BB%E5%88%97/">萱仔求职系列</a><span class="category-list-count">4</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">标签</h3>
    <div class="widget-body">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Anaconda/" rel="tag">Anaconda</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hexo/" rel="tag">Hexo</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B8%B8%E7%94%A8%E5%BA%93/" rel="tag">常用库</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8A%80%E6%9C%AF-nlp-bert-%E7%90%86%E8%AE%BA-%E5%A4%A7%E6%A8%A1%E5%9E%8B/" rel="tag">技术, nlp, bert, 理论, 大模型</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8A%80%E6%9C%AF-nlp-python-bert-transform/" rel="tag">技术, nlp, python, bert, transform</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8A%80%E6%9C%AF-%E6%95%99%E7%A8%8B/" rel="tag">技术, 教程</a><span class="tag-list-count">10</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95-python-kaggle/" rel="tag">推荐算法, python, kaggle</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95-%E7%90%86%E8%AE%BA-python/" rel="tag">推荐算法, 理论, python</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%99%E7%A8%8B/" rel="tag">教程</a><span class="tag-list-count">1</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">标签云</h3>
    <div class="widget-body tagcloud">
      <a href="/tags/Anaconda/" style="font-size: 13px;">Anaconda</a> <a href="/tags/Hexo/" style="font-size: 13px;">Hexo</a> <a href="/tags/Python/" style="font-size: 13px;">Python</a> <a href="/tags/%E5%B8%B8%E7%94%A8%E5%BA%93/" style="font-size: 13px;">常用库</a> <a href="/tags/%E6%8A%80%E6%9C%AF-nlp-bert-%E7%90%86%E8%AE%BA-%E5%A4%A7%E6%A8%A1%E5%9E%8B/" style="font-size: 13px;">技术, nlp, bert, 理论, 大模型</a> <a href="/tags/%E6%8A%80%E6%9C%AF-nlp-python-bert-transform/" style="font-size: 13px;">技术, nlp, python, bert, transform</a> <a href="/tags/%E6%8A%80%E6%9C%AF-%E6%95%99%E7%A8%8B/" style="font-size: 14px;">技术, 教程</a> <a href="/tags/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95-python-kaggle/" style="font-size: 13px;">推荐算法, python, kaggle</a> <a href="/tags/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95-%E7%90%86%E8%AE%BA-python/" style="font-size: 13.5px;">推荐算法, 理论, python</a> <a href="/tags/%E6%95%99%E7%A8%8B/" style="font-size: 13px;">教程</a>
    </div>
  </div>

    
      
  <div class="widget">
    <h3 class="widget-title">归档</h3>
    <div class="widget-body">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/09/">九月 2024</a><span class="archive-list-count">18</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget-body">
      <ul class="recent-post-list list-unstyled no-thumbnail">
        
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E6%96%B0%E9%97%BB%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E9%A1%B9%E7%9B%AE/">新闻文本分类项目</a>
              </p>
              <p class="item-title">
                <a href="/2024/09/05/%E6%97%A7%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E4%B8%8A%E4%BC%A0%E8%AE%B0%E5%BD%95-%E5%A4%A9%E6%B1%A0-%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8NLP_-_%E6%96%B0%E9%97%BB%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/" class="title">旧代码学习上传记录-天池-零基础入门NLP_-_新闻文本分类</a>
              </p>
              <p class="item-date">
                <time datetime="2024-09-05T06:00:00.000Z" itemprop="datePublished">2024-09-05</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E8%90%B1%E4%BB%94%E6%B1%82%E8%81%8C%E7%B3%BB%E5%88%97/">萱仔求职系列</a>
              </p>
              <p class="item-title">
                <a href="/2024/09/05/%E8%90%B1%E4%BB%94%E6%B1%82%E8%81%8C%E7%B3%BB%E5%88%97%E2%80%94%E2%80%941.1_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%A4%8D%E4%B9%A0/" class="title">萱仔求职系列——1.1_机器学习基础知识复习</a>
              </p>
              <p class="item-date">
                <time datetime="2024-09-05T06:00:00.000Z" itemprop="datePublished">2024-09-05</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E8%90%B1%E4%BB%94%E6%B1%82%E8%81%8C%E7%B3%BB%E5%88%97/">萱仔求职系列</a>
              </p>
              <p class="item-title">
                <a href="/2024/09/05/%E8%90%B1%E4%BB%94%E6%B1%82%E8%81%8C%E7%B3%BB%E5%88%97%E2%80%94%E2%80%941.2_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%A4%8D%E4%B9%A0+%E9%83%A8%E5%88%86%E4%BB%A3%E7%A0%81%E5%AE%9E%E6%88%98/" class="title">萱仔求职系列——1.2_机器学习基础知识复习+部分代码实战</a>
              </p>
              <p class="item-date">
                <time datetime="2024-09-05T06:00:00.000Z" itemprop="datePublished">2024-09-05</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E8%90%B1%E4%BB%94%E6%B1%82%E8%81%8C%E7%B3%BB%E5%88%97/">萱仔求职系列</a>
              </p>
              <p class="item-title">
                <a href="/2024/09/05/%E8%90%B1%E4%BB%94%E6%B1%82%E8%81%8C%E7%B3%BB%E5%88%97%E2%80%94%E2%80%943.1_%E5%8A%9B%E6%89%A3%E9%9D%A2%E8%AF%95150%E9%A2%98%E7%9B%AE%E2%80%94%E2%80%94%E6%95%B0%E7%BB%84&%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%AC%AC%E4%B8%80%E5%BC%B9/" class="title">萱仔求职系列——3.1_力扣面试150题目——数组&amp;字符串第一弹</a>
              </p>
              <p class="item-date">
                <time datetime="2024-09-05T06:00:00.000Z" itemprop="datePublished">2024-09-05</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E8%90%B1%E4%BB%94%E6%B1%82%E8%81%8C%E7%B3%BB%E5%88%97/">萱仔求职系列</a>
              </p>
              <p class="item-title">
                <a href="/2024/09/05/%E8%90%B1%E4%BB%94%E6%B1%82%E8%81%8C%E7%B3%BB%E5%88%97%E2%80%94%E2%80%942.1_python%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%A4%8D%E4%B9%A0%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B+%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" class="title">萱仔求职系列——2.1_python基础知识复习——数据类型+数据结构</a>
              </p>
              <p class="item-date">
                <time datetime="2024-09-05T06:00:00.000Z" itemprop="datePublished">2024-09-05</time>
              </p>
            </div>
          </li>
          
      </ul>
    </div>
  </div>
  

    
  </div>
</aside>

  
  
<main class="main" role="main">
  <div class="content">
  <article id="post-萱仔大模型学习记录3.2-BERT算法微调理论和实践Adapter_Tuning、Prefix_Tuning等" class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting">
    
    <div class="article-header">
      
        
  
    <h1 class="article-title" itemprop="name">
      萱仔大模型学习记录3.2-BERT算法微调理论和实践Adapter_Tuning、Prefix_Tuning等
    </h1>
  

      
      <div class="article-meta">
        <span class="article-date">
    <i class="icon icon-calendar-check"></i>
	<a href="/2024/09/04/%E8%90%B1%E4%BB%94%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%953.2-BERT%E7%AE%97%E6%B3%95%E5%BE%AE%E8%B0%83%E7%90%86%E8%AE%BA%E5%92%8C%E5%AE%9E%E8%B7%B5Adapter_Tuning%E3%80%81Prefix_Tuning%E7%AD%89/" class="article-date">
	  <time datetime="2024-09-04T06:00:00.000Z" itemprop="datePublished">2024-09-04</time>
	</a>
</span>
        
  <span class="article-category">
    <i class="icon icon-folder"></i>
    <a class="article-category-link" href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/">大模型学习记录</a>
  </span>

        
  <span class="article-tag">
    <i class="icon icon-tags"></i>
	<a class="article-tag-link-link" href="/tags/%E6%8A%80%E6%9C%AF-%E6%95%99%E7%A8%8B/" rel="tag">技术, 教程</a>
  </span>


        

        <span class="post-comment"><i class="icon icon-comment"></i> <a href="/2024/09/04/%E8%90%B1%E4%BB%94%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%953.2-BERT%E7%AE%97%E6%B3%95%E5%BE%AE%E8%B0%83%E7%90%86%E8%AE%BA%E5%92%8C%E5%AE%9E%E8%B7%B5Adapter_Tuning%E3%80%81Prefix_Tuning%E7%AD%89/#comments" class="article-comment-link">评论</a></span>
        
      </div>
    </div>
    <div class="article-entry marked-body" itemprop="articleBody">
      
        <h3 id="3-Adapter-Tuning"><a href="#3-Adapter-Tuning" class="headerlink" title="3.Adapter Tuning"></a>3.Adapter Tuning</h3><p> 原版论文：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1902/.00751/.pdf">https://arxiv.org/pdf/1902\.00751\.pdf</a></p>
<p> 原版代码：GitHub - google-research&#x2F;adapter-bert</p>
<p><img src="https://i-blog.csdnimg.cn/direct/efe6d6d5a3144eb99246e3b0043a4f30.png"></p>
<p><strong>Adapter Tuning</strong><br> 是一种在预训练模型的基础上进行高效微调的方法。通过插入adapter modules，只需增加少量可训练参数，就能使模型在新任务上取得优异的性能。（我个人感觉这个在使用上和lora有点类似，lora是引入了两个矩阵，在外面训练微调，较低成本实现训练任务。这个是加入一个适配器的模块。<br> <strong>Adapter Modules</strong><br> 是插入到现有预训练模型中的小型网络层。由少量可训练参数组成，通常包括一个下采样层、一个ReLU之类的非线性激活层，以及一个上采样层。（这一点又和计算机视觉中有一点点像，上采样和下采样各有作用，然后加上激活函数的非线性函数，加入到神经网络中可以让网格拟合非线性映射。<br> <strong>Adapter Modules</strong><br> 插入位置通常在Transformer层之间。）</p>
<p> 在适配器微调过程中，预训练模型的参数保持不变。只训练适配器模块的参数，从而实现参数高效的迁移学习。相比于传统的微调，适配器微调只需增加很少的新参数，但能够取得接近或甚至超越全量微调的效果。适配器模块可以独立于任务进行训练，适应多任务学习的需求。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import torch</span><br><span class="line">from transformers import BertModel, BertTokenizer, BertForSequenceClassification, AdapterConfig</span><br><span class="line"></span><br><span class="line"># 加载预训练BERT模型和Tokenizer</span><br><span class="line">model_name = &quot;bert-base-uncased&quot;</span><br><span class="line">tokenizer = BertTokenizer.from_pretrained(model_name)</span><br><span class="line">model = BertForSequenceClassification.from_pretrained(model_name)</span><br><span class="line"></span><br><span class="line"># 冻结BERT主体模型的所有参数</span><br><span class="line">for param in model.bert.parameters():</span><br><span class="line">    param.requires_grad = False</span><br><span class="line"></span><br><span class="line"># 添加适配器模块配置</span><br><span class="line">adapter_config = AdapterConfig(</span><br><span class="line">    hidden_size=64,  # 适配器模块的隐藏层大小</span><br><span class="line">    adapter_non_linearity=&quot;relu&quot;,  # 非线性激活函数</span><br><span class="line">    reduction_factor=16  # 下采样比例</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"># 为分类任务添加适配器</span><br><span class="line">model.add_adapter(&quot;text_classification_adapter&quot;, config=adapter_config)</span><br><span class="line">model.train_adapter(&quot;text_classification_adapter&quot;)</span><br><span class="line"></span><br><span class="line"># 示例输入</span><br><span class="line">inputs = tokenizer(&quot;This is a test sentence.&quot;, return_tensors=&quot;pt&quot;)</span><br><span class="line"></span><br><span class="line"># 模型预测前向传播</span><br><span class="line">outputs = model(**inputs)</span><br><span class="line"></span><br><span class="line"># 打印模型输出</span><br><span class="line">print(outputs.logits)</span><br><span class="line"></span><br><span class="line"># 准备训练数据（以GLUE任务中的MRPC数据集为例）</span><br><span class="line">from datasets import load_dataset</span><br><span class="line">dataset = load_dataset(&quot;glue&quot;, &quot;mrpc&quot;)</span><br><span class="line">train_dataset = dataset[&#x27;train&#x27;]</span><br><span class="line">validation_dataset = dataset[&#x27;validation&#x27;]</span><br><span class="line"></span><br><span class="line"># 数据处理函数</span><br><span class="line">def preprocess_function(examples):</span><br><span class="line">    return tokenizer(examples[&#x27;sentence1&#x27;], examples[&#x27;sentence2&#x27;], truncation=True, padding=True)</span><br><span class="line"></span><br><span class="line"># 预处理数据</span><br><span class="line">train_dataset = train_dataset.map(preprocess_function, batched=True)</span><br><span class="line">validation_dataset = validation_dataset.map(preprocess_function, batched=True)</span><br><span class="line"></span><br><span class="line"># 数据加载器</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)</span><br><span class="line">validation_loader = DataLoader(validation_dataset, batch_size=16)</span><br><span class="line"></span><br><span class="line"># 定义优化器和损失函数</span><br><span class="line">from transformers import AdamW</span><br><span class="line">optimizer = AdamW(model.parameters(), lr=5e-5)</span><br><span class="line">loss_fn = torch.nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"># 训练适配器</span><br><span class="line">model.train()</span><br><span class="line">for epoch in range(3):  # 训练3个epoch</span><br><span class="line">    for batch in train_loader:</span><br><span class="line">        inputs = &#123;k: v.to(model.device) for k, v in batch.items() if k in tokenizer.model_input_names&#125;</span><br><span class="line">        labels = batch[&#x27;label&#x27;].to(model.device)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        outputs = model(**inputs)</span><br><span class="line">        loss = loss_fn(outputs.logits, labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">    print(f&quot;Epoch &#123;epoch + 1&#125;: Loss &#123;loss.item()&#125;&quot;)</span><br><span class="line"></span><br><span class="line"># 验证模型</span><br><span class="line">model.eval()</span><br><span class="line">correct_predictions = 0</span><br><span class="line">total_predictions = 0</span><br><span class="line">with torch.no_grad():</span><br><span class="line">    for batch in validation_loader:</span><br><span class="line">        inputs = &#123;k: v.to(model.device) for k, v in batch.items() if k in tokenizer.model_input_names&#125;</span><br><span class="line">        labels = batch[&#x27;label&#x27;].to(model.device)</span><br><span class="line">        outputs = model(**inputs)</span><br><span class="line">        predictions = torch.argmax(outputs.logits, dim=-1)</span><br><span class="line">        correct_predictions += (predictions == labels).sum().item()</span><br><span class="line">        total_predictions += labels.size(0)</span><br><span class="line">accuracy = correct_predictions / total_predictions</span><br><span class="line">print(f&quot;Validation Accuracy: &#123;accuracy&#125;&quot;)</span><br><span class="line"></span><br><span class="line"># 保存适配器</span><br><span class="line">model.save_adapter(&quot;text_classification_adapter&quot;, &quot;output_adapter_directory&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>









<h3 id="4-Prefix-Tuning输入增加可训练的上下文前缀"><a href="#4-Prefix-Tuning输入增加可训练的上下文前缀" class="headerlink" title="4.Prefix Tuning输入增加可训练的上下文前缀"></a>4.Prefix Tuning输入增加可训练的上下文前缀</h3><p> 原版论文：<br> <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2101.00190.pdf" title="https://arxiv.org/pdf/2101.00190.pdf">https://arxiv.org/pdf/2101.00190.pdf</a> </p>
<p> 原版代码：</p>
<p><img src="https://i-blog.csdnimg.cn/direct/184bb99124584ebeb5d4e06af1de877c.png"></p>
<p> Fine-tuning是利用大型预训练语言模型来执行下游任务的默认方式。然而，微调会修改所有语言模型的参数，因此需要为每个任务存储一份完整的副本。本文提出了一种轻量级的微调替代方法——前缀调优prefix-tuning，专用于自然语言生成任务。前缀调优保持语言模型参数不变，仅优化一个小的任务特定的连续向量（称为前缀）。前缀调优受提示（prompting）的启发，允许后续的token关注这个前缀，仿佛它们是“虚拟token”。这篇论文将前缀调优应用于GPT-2进行表格到文本生成，以及BART进行摘要生成。结果表明，通过仅学习0.1%的参数，前缀调优在完整数据集环境中获得了与全量微调相当的性能，在低数据环境中表现优于微调，并且在训练时未见过主题的例子上具有更好的外推能力。</p>
<p><strong>Prefix Tuning</strong><br> 是一种在预训练语言模型（如 BERT 或 GPT-2）基础上进行高效微调的方法。与传统的微调方式不同，Prefix Tuning 只调整少量的前缀参数，而不修改原始模型的参数，从而在多个任务之间实现高效迁移。</p>
<p><img src="https://i-blog.csdnimg.cn/direct/90fab1326f604ce68fda4c25c2773666.png"></p>
<ol>
<li><h4 id="前缀参数（Prefix-Parameters）"><a href="#前缀参数（Prefix-Parameters）" class="headerlink" title="前缀参数（Prefix Parameters）"></a><strong>前缀参数（Prefix Parameters）</strong></h4></li>
</ol>
<p> ：</p>
<pre><code>* 前缀参数是在每层 Transformer 网络的输入前增加的一组可训练参数。
* 这些参数在模型进行任务特定的微调时可以独立更新，而无需调整原始模型的参数。
</code></pre>
<ol start="2">
<li><h4 id="冻结预训练模型"><a href="#冻结预训练模型" class="headerlink" title="冻结预训练模型"></a><strong>冻结预训练模型</strong></h4></li>
</ol>
<p> ：</p>
<pre><code>* 在 Prefix Tuning 过程中，预训练模型的参数保持不变。
* 只训练前缀参数，从而实现高效的参数更新和迁移学习。
</code></pre>
<ol start="3">
<li><h4 id="高效微调"><a href="#高效微调" class="headerlink" title="高效微调"></a><strong>高效微调</strong></h4></li>
</ol>
<p> ：</p>
<pre><code>* 相比于传统的微调，Prefix Tuning 只需调整少量的前缀参数，但能够取得接近或甚至超越全量微调的效果。
* 前缀参数可以独立于任务进行训练，适应多任务学习的需求。
</code></pre>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ol>
<li><p><strong>传统微调的局限性</strong><br> ：</p>
<ul>
<li>修改所有语言模型参数，需要为每个任务存储一个完整的模型副本。</li>
</ul>
</li>
<li><p><strong>前缀调优的优势</strong><br> ：</p>
<ul>
<li>保持语言模型参数不变，仅优化前缀参数。</li>
<li>通过仅学习0.1%的参数，前缀调优在全数据集设置中获得了可比的性能，在低数据设置中表现优于微调，并在训练中未见的主题上表现更好。</li>
</ul>
</li>
<li><p><strong>应用场景</strong><br> ：</p>
<ul>
<li>前缀调优适用于自然语言生成任务，如表格到文本生成和摘要生成。</li>
</ul>
</li>
</ol>
<p> 所有P-tuning都是基于优化连续的prefix或者prompt的思想。调整软提示优于先前对离散提示优化的工作。Prompt-tuning的工作表明全量微调和P*-tuning之间的性能差距随着模型的大小增大而消失。</p>
<p> 5.Prompt Tuning输入增加可训练的嵌入向量提示</p>

      
    </div>
    <div class="article-footer">
      <blockquote class="mt-2x">
  <ul class="post-copyright list-unstyled">
    
    <li class="post-copyright-link hidden-xs">
      <strong>本文链接：</strong>
      <a href="http://example.com/2024/09/04/%E8%90%B1%E4%BB%94%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%953.2-BERT%E7%AE%97%E6%B3%95%E5%BE%AE%E8%B0%83%E7%90%86%E8%AE%BA%E5%92%8C%E5%AE%9E%E8%B7%B5Adapter_Tuning%E3%80%81Prefix_Tuning%E7%AD%89/" title="萱仔大模型学习记录3.2-BERT算法微调理论和实践Adapter_Tuning、Prefix_Tuning等" target="_blank" rel="external">http://example.com/2024/09/04/萱仔大模型学习记录3.2-BERT算法微调理论和实践Adapter_Tuning、Prefix_Tuning等/</a>
    </li>
    
    <li class="post-copyright-license">
      <strong>版权声明： </strong> 本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by/4.0/deed.zh" target="_blank" rel="external">CC BY 4.0 CN协议</a> 许可协议。转载请注明出处！
    </li>
  </ul>
</blockquote>


<div class="panel panel-default panel-badger">
  <div class="panel-body">
    <figure class="media">
      <div class="media-left">
        <a href="https://blog.csdn.net/qq_44117805?" target="_blank" class="img-burn thumb-sm visible-lg">
          <img src="/images/avatar.jpg" class="img-rounded w-full" alt="">
        </a>
      </div>
      <div class="media-body">
        <h3 class="media-heading"><a href="https://blog.csdn.net/qq_44117805?" target="_blank"><span class="text-dark">萱仔</span><small class="ml-1x">萱仔的自我学习记录，冲冲冲！</small></a></h3>
        <div>个人简介</div>
      </div>
    </figure>
  </div>
</div>


    </div>
  </article>
  
    
  <section id="comments">
  	
      <div id="vcomments"></div>
    
  </section>


  
</div>

  <nav class="bar bar-footer clearfix" data-stick-bottom>
  <div class="bar-inner">
  
  <ul class="pager pull-left">
    
    <li class="prev">
      <a href="/2024/09/04/%E8%90%B1%E4%BB%94%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%952.1-BERT%E7%AE%97%E6%B3%95%E8%AE%BA%E6%96%87%E5%92%8C%E5%AE%9E%E8%B7%B5/" title="萱仔大模型学习记录2.1-BERT算法论文和实践"><i class="icon icon-angle-left" aria-hidden="true"></i><span>&nbsp;&nbsp;上一篇</span></a>
    </li>
    
    
    <li class="next">
      <a href="/2024/09/04/%E8%90%B1%E4%BB%94%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%955-langchain%E5%AE%9E%E6%88%98/" title="萱仔大模型学习记录5-langchain实战"><span>下一篇&nbsp;&nbsp;</span><i class="icon icon-angle-right" aria-hidden="true"></i></a>
    </li>
    
    
  </ul>
  
  
  
  <div class="bar-right">
    
    <div class="share-component" data-sites="weibo,qq,wechat,facebook,twitter" data-mobile-sites="weibo,qq,qzone"></div>
    
  </div>
  </div>
</nav>
  


</main>

  <footer class="footer" itemscope itemtype="http://schema.org/WPFooter">
	
	
    <ul class="social-links">
    	
        <li><a href="https://blog.csdn.net/qq_44117805?" target="_blank" title="CSDN" data-toggle=tooltip data-placement=top><i class="icon icon-CSDN"></i></a></li>
        
        <li><a href="/atom.xml" target="_blank" title="Rss" data-toggle=tooltip data-placement=top><i class="icon icon-rss"></i></a></li>
        
    </ul>

    <div class="copyright">
    	
        <div class="publishby">
        	Theme by <a href="https://github.com/cofess" target="_blank"> cofess </a>base on <a href="https://github.com/cofess/hexo-theme-pure" target="_blank">pure</a>.
        </div>
    </div>
</footer>
  <script src="//cdn.jsdelivr.net/npm/jquery@1.12.4/dist/jquery.min.js"></script>
<script>
window.jQuery || document.write('<script src="js/jquery.min.js"><\/script>')
</script>

<script src="/js/plugin.min.js"></script>


<script src="/js/application.js"></script>


    <script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>






   




   
    
  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/valine"></script>
  <script type="text/javascript">
  var GUEST = ['nick', 'mail', 'link'];
  var meta = 'nick,mail,link';
  meta = meta.split(',').filter(function(item) {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#vcomments',
    verify: false,
    notify: false,
    appId: '',
    appKey: '',
    placeholder: 'Just go go',
    avatar: 'mm',
    meta: meta,
    pageSize: '10' || 10,
    visitor: false
  });
  </script>

     







</body>
</html>